# Epic: Audit Findings

Generated by Spec Auditor

## Issue: Refactor Data Models for Tiered Lenses and Measures

## User Story
As a Semantic Steward, I want to define Lenses with specific Tier rules and composition logic, So that the system can accurately evaluate performance across different organizational levels (Force vs Group vs Team).

## Acceptance Criteria
- [ ] `MeasureDefinition` in `holon.ts` updated to include `dsl` (string), `unitOfEval`, and `dependencies` (array) per Spec Sec 8.
- [ ] `LensDefinition` in `holon.ts` updated to replace generic `logic` string with structured `tierRules` (array), `measureRefs` (array), and `compositionRules` (array).
- [ ] `PublishedLens` interface created to represent the immutable, compiled artifact (Spec Sec 2.4 & 8) containing signatures and validity windows.
- [ ] `TierRule` interface defined to handle aggregation methods (e.g., 'weighted', 'min', 'mean') per Spec Sec 4.2.

**Related Files:**
- `packages/som-shared-types/src/holon.ts`
- `packages/som-shared-types/src/measure.ts`

**Labels**: audit-finding, High

---

## Issue: Implement Lens Execution API Surface

## User Story
As a BI Engineer, I want a stable, pre-approved API contract for evaluating Lenses, So that I can build dashboards that consume semantic products without writing ad-hoc SQL or relying on dynamic routes.

## Acceptance Criteria
- [ ] `APIRoutes` class updated to include specific `GET /api/lens/{lensId}/evaluate` route (Spec Sec 4.6.1).
- [ ] `GET /api/lens/{lensId}/metadata` implemented to return explainability data.
- [ ] `GET /api/lens/{lensId}/units` implemented to list applicable units for the lens scope.
- [ ] API routes enforce IL5 safety by being statically defined (no dynamic route generation at runtime).

**Related Files:**
- `apps/som-tier0/src/api/routes.ts`
- `apps/som-tier0/src/api/api-types.ts`
- `apps/som-tier0/src/api/api-server.ts`

**Labels**: audit-finding, Critical

---

## Issue: Develop Lens Execution Kernel (Compute Engine)

## User Story
As an Analyst, I want the system to automatically compute Lens scores using a centralized kernel, So that all dashboards report the same 'computable truth' regardless of where the data is displayed.

## Acceptance Criteria
- [ ] `LensExecutionKernel` class created to orchestrate evaluation.
- [ ] Logic implemented to resolve a `PublishedLens` and its dependency graph of Measures.
- [ ] Arithmetic engine implemented to process the Measure DSL (e.g., simple math, aggregation).
- [ ] Tier-specific aggregation logic implemented (handling rules for Unit vs Force levels).
- [ ] Execution generates `LensEvaluated` events (Spec Sec 4.6.3) containing scores, breakdowns, and interpretation.

**Related Files:**
- `apps/som-tier0/src/lenses/kernel.ts`
- `apps/som-tier0/src/lenses/evaluator.ts`

**Labels**: audit-finding, High

---

## Issue: Implement Lens Compiler and Publishing Workflow

## User Story
As a Governance Officer, I want to 'Publish' a Lens to create a versioned, immutable snapshot, So that historical data remains explainable even if the definition changes later.

## Acceptance Criteria
- [ ] `LensCompiler` service implemented to validate draft definitions against the schema.
- [ ] Logic to snapshot all referenced measures and rules into a single JSON blob.
- [ ] Validation logic ensures no circular dependencies and data availability (Spec Sec 4.3).
- [ ] Publishing action generates a `PublishedLens` artifact and signs the version metadata.

**Related Files:**
- `apps/som-tier0/src/lenses/compiler.ts`
- `apps/som-tier0/src/lenses/validator.ts`

**Labels**: audit-finding, Medium

---

